{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Speech to text with Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in ./ispeech/lib/python3.7/site-packages (0.18.0)\n",
      "Requirement already satisfied: PyAudio in ./ispeech/lib/python3.7/site-packages (0.2.11)\n",
      "Requirement already satisfied: pydub in ./ispeech/lib/python3.7/site-packages (0.23.1)\n",
      "Requirement already satisfied: SpeechRecognition in ./ispeech/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied: google-cloud-storage in ./ispeech/lib/python3.7/site-packages (1.26.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in ./ispeech/lib/python3.7/site-packages (from google-cloud-storage) (1.3.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in ./ispeech/lib/python3.7/site-packages (from google-cloud-storage) (1.11.3)\n",
      "Requirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in ./ispeech/lib/python3.7/site-packages (from google-cloud-storage) (0.5.0)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.16.0 in ./ispeech/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (40.8.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (1.14.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (4.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.51.0)\n",
      "Requirement already satisfied: pytz in ./ispeech/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (2019.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (3.11.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./ispeech/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=1.11.0->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (2019.11.28)\n",
      "Requirement already up-to-date: google-cloud-speech in ./ispeech/lib/python3.7/site-packages (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in ./ispeech/lib/python3.7/site-packages (from google-cloud-speech) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.11.3)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.11.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in ./ispeech/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in ./ispeech/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./ispeech/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in ./ispeech/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#Install fuzzywuzzy for keyword match\n",
    "!{sys.executable} -m pip install fuzzywuzzy\n",
    "\n",
    "#intall pyaudio for access to local microphone\n",
    "!{sys.executable} -m pip install PyAudio\n",
    "\n",
    "#Install pydub for silence detection and for handling Audio files.\n",
    "!{sys.executable} -m pip install pydub\n",
    "\n",
    "#Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install SpeechRecognition\n",
    "\n",
    "#Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install google-cloud-storage\n",
    "\n",
    " #Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Audio Book and Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28153636"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "## These audio_books are in the public domain\n",
    "url = 'http://www.archive.org/download/alices_adventures/alices_adventures_64kb_mp3.zip'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "## we save the zip_file in our directory\n",
    "open('data/Aliceinwonderland.zip', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "aliceinwonderland_01_carroll_64kb.mp3          2007-05-19 00:31:06      3538287\n",
      "aliceinwonderland_02_carroll_64kb.mp3          2007-05-19 00:32:44      3086679\n",
      "aliceinwonderland_03_carroll_64kb.mp3          2007-05-19 00:32:30      3286894\n",
      "aliceinwonderland_04_carroll_64kb.mp3          2007-05-19 00:32:08      3569020\n",
      "aliceinwonderland_05_carroll_64kb.mp3          2007-05-19 00:31:20      3142903\n",
      "aliceinwonderland_06_carroll_64kb.mp3          2007-05-19 00:31:32      2640087\n",
      "aliceinwonderland_07_carroll_64kb.mp3          2007-05-19 00:31:54      1746909\n",
      "aliceinwonderland_08_carroll_64kb.mp3          2007-05-19 00:31:46      3518858\n",
      "aliceinwonderland_09_carroll_64kb.mp3          2007-05-19 00:32:16      1794561\n",
      "aliceinwonderland_10_carroll_64kb.mp3          2007-05-19 00:32:52      1827576\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## Extracting the zip_files\n",
    "\n",
    "# importing required modules \n",
    "from zipfile import ZipFile \n",
    "\n",
    "# specifying the zip file name \n",
    "file_name = \"data/Aliceinwonderland.zip\"\n",
    "\n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(file_name, 'r') as zipfile: \n",
    "    # printing all the contents of the zip file \n",
    "    zipfile.printdir() \n",
    "\n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zipfile.extractall(path = 'data/Alice/') \n",
    "    print('Done!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio data with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing a chapter into chunks and indexing\n",
    "\n",
    "In this section we will use SpeechRecognition and Pydub packages only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import speech_recognition as  sr \n",
    "import  os\n",
    "from pydub import AudioSegment\n",
    "from  pydub.silence  import  split_on_silence\n",
    "from pydub.silence import detect_nonsilent\n",
    "from pydub.playback import play\n",
    "def silence_based_conversion(path = \"\"): \n",
    "\n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_mp3(path)\n",
    "\n",
    "    # open a file where we will concatenate \n",
    "    # and store the recognized text \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "    new_list = []\n",
    "    # split track where silence is 0.5 seconds \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 750, \n",
    "\n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -40, \n",
    "        keep_silence= 0\n",
    "    ) \n",
    "\n",
    "    ranges = detect_nonsilent(song, min_silence_len= 750, silence_thresh= -40)\n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "\n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('audio_chunks') \n",
    "\n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    start = 0\n",
    "    for chunk, rng in zip(chunks, ranges):\t\n",
    "        \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 300) \n",
    "\n",
    "        # add 0.5 sec silence to beginning and \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "\n",
    "        # export audio chunk and save it in \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "\n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "\n",
    "#         print(\"Processing chunk \"+str(i)) \n",
    "\n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "\n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "\n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            # r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.listen(source)\n",
    "\n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\".\")\n",
    "            new_list.append((i,rng, rec))\n",
    "\n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "\n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "\n",
    "        i += 1\n",
    "        start += len(chunk) + 1000\n",
    "\n",
    "    os.chdir('/Users/muratguner/Documents/experiments/meet_up_presentation') \n",
    "    \n",
    "    return new_list\n",
    "#/Users/muratguner/Documents/experiments/meet_up_presentation/data/Alice/aliceinwonderland_01_carroll_64kb.mp3\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    print('Enter the audio file path') \n",
    "\n",
    "    path = input() \n",
    "\n",
    "    text = silence_based_conversion(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Keyword match with FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 100 she found herself in a long low Hall which was lit up by a row of lamps hanging from the roof\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "for (i, interval,sentence) in text:\n",
    "    score = fuzz.token_set_ratio('long hall', sentence)\n",
    "    if score > 70: \n",
    "        print(i, score, sentence)\n",
    "        song = AudioSegment.from_mp3(\"/Users/muratguner/Documents/experiments/meet_up_presentation/data/Alice/aliceinwonderland_01_carroll_64kb.mp3\")\n",
    "        play(song[interval[0]:interval[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking input keyword from the microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a keyword to search in Alice in Wonderland\n",
      "Attempt_0 Speak!\n",
      "I didn't catch that. What did you say?\n",
      "\n",
      "Attempt_1 Speak!\n",
      "down\n",
      "8 100 down the rabbit\n",
      "Do you want to hear next? Say next or continue\n",
      "You said: next\n",
      "True\n",
      "13 100 but when the rabbit actually took a watch out of its waistcoat pocket and looked at it and then hurried on Alice started to her feet or it flashed across her mind that she had never before seen a rabbit with either a waistcoat pocket or watch to take out of it and burning with curiosity she ran across the field after it and was just in time to see it pop down a large rabbit hole under the Hedge in another moment down went Alice after\n",
      "Do you want to hear next? Say next or continue\n",
      "You said: next\n",
      "True\n",
      "14 100 the rabbit hole with straight on like a tunnel for some way and then dip suddenly down there suddenly that Alice had not a moment to think about stopping herself before she found herself falling down what seemed to be a very deep well\n",
      "Do you want to hear next? Say next or continue\n",
      "You said: next\n",
      "True\n",
      "15 100 either the world is very deep or she still very slowly but she had plenty of times she went down to look about her\n",
      "Do you want to hear next? Say next or continue\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-5b9383f39b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Do you want to hear next? Say next or continue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognize_speech_from_mic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicrophone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mgate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transcription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'next'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You said: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transcription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'success'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    \"\"\"Transcribe speech from recorded from `microphone`.\n",
    "    Returns a dictionary with three keys:\n",
    "    \"success\": a boolean indicating whether or not the API request was\n",
    "               successful\n",
    "    \"error\":   `None` if no error occured, otherwise a string containing\n",
    "               an error message if the API could not be reached or\n",
    "               speech was unrecognizable\n",
    "    \"transcription\": `None` if speech could not be transcribed,\n",
    "               otherwise a string containing the transcribed text\n",
    "    \"\"\"\n",
    "    # check that recognizer and microphone arguments are appropriate type\n",
    "    if not isinstance(recognizer, sr.Recognizer):\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\n",
    "\n",
    "    if not isinstance(microphone, sr.Microphone):\n",
    "        raise TypeError(\"`microphone` must be `Microphone` instance\")\n",
    "\n",
    "    # adjust the recognizer sensitivity to ambient noise and record audio\n",
    "    # from the microphone\n",
    "    with microphone as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    # set up the response object\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    "\n",
    "    # try recognizing the speech in the recording\n",
    "    # if a RequestError or UnknownValueError exception is caught,\n",
    "    #     update the response object accordingly\n",
    "    try:\n",
    "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
    "    except sr.RequestError:\n",
    "        # API was unreachable or unresponsive\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable\"\n",
    "    except sr.UnknownValueError:\n",
    "        # speech was unintelligible\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create recognizer and mic instances\n",
    "    recognizer = sr.Recognizer()\n",
    "    microphone = sr.Microphone()\n",
    "    PROMPT_LIMIT = 5\n",
    "    # format the instructions string\n",
    "    instructions = (\n",
    "        \"Give me a keyword to search in Alice in Wonderland\"\n",
    "    )\n",
    "\n",
    "    # show instructions and wait 3 seconds before starting the game\n",
    "    print(instructions)\n",
    "    \n",
    "    song = AudioSegment.from_mp3(\"/Users/muratguner/Documents/experiments/meet_up_presentation/data/Alice/aliceinwonderland_01_carroll_64kb.mp3\")\n",
    "\n",
    "    \n",
    "    for j in range(PROMPT_LIMIT):\n",
    "        print('Attempt_{} Speak!'.format(j))\n",
    "        keyword = recognize_speech_from_mic(recognizer, microphone)\n",
    "        if keyword[\"transcription\"]:\n",
    "            break\n",
    "        if not keyword[\"success\"]:\n",
    "            break\n",
    "        print(\"I didn't catch that. What did you say?\\n\")  \n",
    "    print(keyword['transcription'])\n",
    "    for (i, interval,sentence) in text:\n",
    "        score = fuzz.token_set_ratio(keyword['transcription'], sentence)\n",
    "        if score > 95: \n",
    "            print(i, score, sentence)\n",
    "            play(song[interval[0]:interval[1]])\n",
    "            print('Do you want to hear next? Say next or continue')\n",
    "            gate = recognize_speech_from_mic(recognizer, microphone)\n",
    "            if gate['transcription'].lower() == 'next':\n",
    "                print('You said: {}'.format(gate['transcription']))\n",
    "                print(gate['success'])\n",
    "                continue\n",
    "            elif gate['transcription'].lower() == 'continue':\n",
    "                print(gate['transcription'])\n",
    "                play(song[interval[1]-5*1000: interval[1]+15*1000])\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Resources:\n",
    "\n",
    "[Speech Recognition](https://pypi.org/project/SpeechRecognition/)\n",
    "\n",
    "[For taking the input from microphone](https://github.com/realpython/python-speech-recognition/blob/master/guessing_game.py)\n",
    "\n",
    "[For the silence detection](https://github.com/jiaaro/pydub/blob/master/pydub/silence.py)\n",
    "\n",
    "[For keyword matching with the text](https://pypi.org/project/fuzzywuzzy/)\n",
    "\n",
    "[Alice in Wonderland Text](https://www.gutenberg.org/files/11/11-h/11-h.htm#chap01)\n",
    "\n",
    "[Alice in Wonderland Audiobook](https://archive.org/details/alices_adventures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Silence and Non_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.silence  import  detect_silence\n",
    "from pydub.silence  import detect_nonsilent\n",
    "path = \"/Users/muratguner/Documents/experiments/meet_up_presentation/data/Alice/aliceinwonderland_01_carroll_64kb.mp3\"\n",
    "song = AudioSegment.from_mp3(path)\n",
    "\n",
    "\n",
    "nonsilence_range = detect_nonsilent(song[:30*1000], min_silence_len=750, silence_thresh= -40)\n",
    "\n",
    "splitted_audio = split_on_silence(audio_segment=song[:30*1000], min_silence_len= 750, keep_silence= 300, silence_thresh= -40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Timestamps with Google_Cloud_Speech_Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Dividing the audio files into 30 seconds pieces\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Audio = AudioSegment.from_mp3(\"/Users/muratguner/Documents/experiments/google_cloud_speech/resources/alices_adventures_64kb_mp3/aliceinwonderland_03_carroll_64kb.mp3\")\n",
    "Audio = AudioSegment.from_mp3(\"/Users/muratguner/Documents/experiments/google_cloud_speech/resources/alices_adventures_64kb_mp3/aliceinwonderland_01_carroll_64kb.mp3\")\n",
    "\n",
    "os.chdir(\"/Users/muratguner/Documents/experiments/meet_up_presentation/\")\n",
    "\n",
    "try: \n",
    "    os.mkdir('data/parts_of_chapter_1') \n",
    "except(FileExistsError): \n",
    "    pass\n",
    "os.chdir('data/parts_of_chapter_1') \n",
    "\n",
    "i = 0\n",
    "\n",
    "for t1 in range(0, len(Audio), 30*1000):\n",
    "    new_audio = Audio[t1: t1+30*1000]\n",
    "    new_audio.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\")\n",
    "    i+=1\n",
    "os.chdir(\"/Users/muratguner/Documents/experiments/meet_up_presentation/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 1 divided into 30 seconds pieces and recorded at data/parts_of_chapter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "def sample_long_running_recognize(storage_uri):\n",
    "    \"\"\"\n",
    "    Print start and end time of each word spoken in audio file from Cloud Storage\n",
    "\n",
    "    Args:\n",
    "      storage_uri URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]\n",
    "    \"\"\"\n",
    "    \n",
    "    credentials = service_account.Credentials.from_service_account_file('google_credentials.json')\n",
    "\n",
    "\n",
    "    client = speech_v1.SpeechClient(credentials=credentials)\n",
    "\n",
    "    # storage_uri = 'gs://cloud-samples-data/speech/brooklyn_bridge.flac'\n",
    "\n",
    "    # When enabled, the first result returned by the API will include a list\n",
    "    # of words and the start and end time offsets (timestamps) for those words.\n",
    "    enable_word_time_offsets = True\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "    config = {\n",
    "        \"enable_word_time_offsets\": enable_word_time_offsets,\n",
    "        \"language_code\": language_code,\n",
    "    }\n",
    "#   audio = {\"uri\": storage_uri}\n",
    "\n",
    "    with io.open(storage_uri, \"rb\") as f:\n",
    "        content = f.read()\n",
    "    audio = {\"content\": content}\n",
    "\n",
    "\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "    print(u\"Waiting for operation to complete...\")\n",
    "    response = operation.result()\n",
    "#     print(response)\n",
    "    # The first result includes start and end time word offsets\n",
    "    result = response.results[0]\n",
    "    # First alternative is the most probable result\n",
    "    alternative = result.alternatives[0]\n",
    "    print(alternative.transcript, alternative.words[1].start_time.seconds ,alternative.words[-1].end_time.seconds)\n",
    "#     print(u\"Transcript: {}\".format(alternative.transcript))\n",
    "    # Print the start and end time of each word\n",
    "#     for word in alternative.words.:\n",
    "#         print(u\"Word: {}\".format(word.word))\n",
    "# #         print(\n",
    "# #             u\"Start time: {} seconds {} nanos\".format(\n",
    "# #                 word.start_time.seconds, word.start_time.nanos\n",
    "# #             )\n",
    "# #         )\n",
    "# #         print(\n",
    "# #             u\"End time: {} seconds {} nanos\".format(\n",
    "# #                 word.end_time.seconds, word.end_time.nanos\n",
    "# #             )\n",
    "# #         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path = \"/Users/muratguner/Documents/experiments/meet_up_presentation/data/parts_of_chapter_1/chunk5.wav\"\n",
    "sample_long_running_recognize(local_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With speech_v1 and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1\n",
    "\n",
    "def sample_recognize(content):\n",
    "    \"\"\"\n",
    "    Transcribe a short audio file using synchronous speech recognition\n",
    "\n",
    "    Args:\n",
    "      local_file_path Path to local audio file, e.g. /path/audio.wav\n",
    "    \"\"\"\n",
    "    credentials = service_account.Credentials.from_service_account_file('google_credentials.json')\n",
    "\n",
    "    client = speech_v1.SpeechClient(credentials = credentials)\n",
    "\n",
    "    # local_file_path = 'resources/brooklyn_bridge.raw'\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 22000\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "    config = {\n",
    "        \"language_code\": language_code,\n",
    "        \"sample_rate_hertz\": sample_rate_hertz,\n",
    "        \"encoding\": encoding,\n",
    "        \"enable_word_time_offsets\": True\n",
    "    }\n",
    "    audio = {\"content\": content}\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    i = 0\n",
    "    for result in response.results:\n",
    "        # First alternative is the most probable result\n",
    "        alternative = result.alternatives[0]\n",
    "        print(t1,u\"Transcript: {}{}\".format(alternative.transcript, i))\n",
    "        for word in alternative.words:\n",
    "            print(u\"Word: {}\".format(word.word))\n",
    "            print(\n",
    "            u\"Start time: {} seconds {} nanos\".format(\n",
    "                word.start_time.seconds, word.start_time.nanos\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "              u\"End time: {} seconds {} nanos\".format(\n",
    "                  word.end_time.seconds, word.end_time.nanos\n",
    "                  )\n",
    "              )\n",
    "\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio = AudioSegment.from_mp3(local_file_path)\n",
    "\n",
    "\n",
    "\n",
    "type(Audio.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "there was nothing else to do so Alliston began talking to herself Dino will miss me very much tonight I should think. It was the cat I hope they'll remember her saucer of milk at tea-time Dynamite deer wish you were down here with me Alice felt that she was dozing off when suddenly dumped down She Came Upon a heap of sticks and dry leaves and the phone is over 0 22\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing corresponding Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's play the audio file first\n",
    "\n",
    "from pydub.playback import play\n",
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_mp3(local_file_path)\n",
    "\n",
    "play(song[: 10*1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our first Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's play the audio file first\n",
    "\n",
    "from pydub.playback import play\n",
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_mp3(\"data/Alice/aliceinwonderland_01_carroll_64kb.mp3\")\n",
    "\n",
    "play(song[: 10*1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1\n",
    "from google.cloud.speech_v1 import enums\n",
    "import io\n",
    "\n",
    "\n",
    "def sample_recognize(local_file_path):\n",
    "    \"\"\"\n",
    "    Transcribe a short audio file using synchronous speech recognition\n",
    "\n",
    "    Args:\n",
    "      local_file_path Path to local audio file, e.g. /path/audio.wav\n",
    "    \"\"\"\n",
    "    credentials = service_account.Credentials. from_service_account_file('google_credentials.json')\n",
    "\n",
    "    client = speech_v1p1beta1.SpeechClient(credentials= credentials)\n",
    "\n",
    "    # local_file_path = 'resources/brooklyn_bridge.raw'\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 22050\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "    config = {\n",
    "        \"language_code\": language_code,\n",
    "        \"sample_rate_hertz\": sample_rate_hertz,\n",
    "        \"encoding\": encoding,\n",
    "    }\n",
    "    with io.open(local_file_path, \"rb\") as f:\n",
    "        content = f.read()\n",
    "    audio = {\"content\": content}\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    for result in response.results:\n",
    "        # First alternative is the most probable result\n",
    "        alternative = result.alternatives[0]\n",
    "        print(u\"Transcript: {}\".format(alternative.transcript))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: for a minute or two she stood looking at the house when suddenly a footman and Livery came running out of the wood judging by his face only she would have called him a fish and wrapped loudly at the door with his knuckles is opened by another freaking delivery with a round face and large eyes like a frog\n"
     ]
    }
   ],
   "source": [
    "sample_recognize(local_file_path= \"data/chunk7.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "# from transcribe_short_audio import sample_recognize\n",
    "from google.cloud import speech_v1p1beta1\n",
    "from google.cloud.speech_v1 import enums\n",
    "import io\n",
    "from pydub.playback import play\n",
    "\n",
    "## We cannot just pass the json credentials\n",
    "\n",
    "## For more details: https://github.com/googleapis/google-cloud-python/issues/5349\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 Transcript: recorded by Kirsten ferreri0\n",
      "Word: recorded\n",
      "Confidence: 1.0\n",
      "Start time: 0 seconds 800000000 nanos\n",
      "End time: 1 seconds 500000000 nanos\n",
      "Word: by\n",
      "Confidence: 1.0\n",
      "Start time: 1 seconds 500000000 nanos\n",
      "End time: 1 seconds 600000000 nanos\n",
      "Word: Kirsten\n",
      "Confidence: 0.8100687265396118\n",
      "Start time: 1 seconds 600000000 nanos\n",
      "End time: 2 seconds 100000000 nanos\n",
      "Word: ferreri\n",
      "Confidence: 0.6041839718818665\n",
      "Start time: 2 seconds 100000000 nanos\n",
      "End time: 2 seconds 600000000 nanos\n",
      "15000 Transcript:  Alice's Adventures in Wonderland by Lewis Carroll chapter 3 a caucus race1\n",
      "Word: Alice's\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 3 seconds 500000000 nanos\n",
      "End time: 4 seconds 200000000 nanos\n",
      "Word: Adventures\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 4 seconds 200000000 nanos\n",
      "End time: 4 seconds 500000000 nanos\n",
      "Word: in\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 4 seconds 500000000 nanos\n",
      "End time: 4 seconds 700000000 nanos\n",
      "Word: Wonderland\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 4 seconds 700000000 nanos\n",
      "End time: 4 seconds 900000000 nanos\n",
      "Word: by\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 4 seconds 900000000 nanos\n",
      "End time: 5 seconds 900000000 nanos\n",
      "Word: Lewis\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 5 seconds 900000000 nanos\n",
      "End time: 6 seconds 0 nanos\n",
      "Word: Carroll\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 6 seconds 0 nanos\n",
      "End time: 6 seconds 300000000 nanos\n",
      "Word: chapter\n",
      "Confidence: 0.9876290559768677\n",
      "Start time: 6 seconds 300000000 nanos\n",
      "End time: 7 seconds 900000000 nanos\n",
      "Word: 3\n",
      "Confidence: 0.7721448540687561\n",
      "Start time: 7 seconds 900000000 nanos\n",
      "End time: 8 seconds 100000000 nanos\n",
      "Word: a\n",
      "Confidence: 0.8926761150360107\n",
      "Start time: 8 seconds 100000000 nanos\n",
      "End time: 9 seconds 0 nanos\n",
      "Word: caucus\n",
      "Confidence: 0.7880687713623047\n",
      "Start time: 9 seconds 0 nanos\n",
      "End time: 9 seconds 400000000 nanos\n",
      "Word: race\n",
      "Confidence: 0.7874109745025635\n",
      "Start time: 9 seconds 400000000 nanos\n",
      "End time: 9 seconds 500000000 nanos\n"
     ]
    }
   ],
   "source": [
    "def sample_recognize(content):\n",
    "    \"\"\"\n",
    "    Transcribe a short audio file using synchronous speech recognition\n",
    "\n",
    "    Args:\n",
    "      local_file_path Path to local audio file, e.g. /path/audio.wav\n",
    "    \"\"\"\n",
    "    credentials = service_account.Credentials. from_service_account_file('google_credentials.json')\n",
    "\n",
    "    client = speech_v1p1beta1.SpeechClient(credentials= credentials)\n",
    "\n",
    "    # local_file_path = 'resources/brooklyn_bridge.raw'\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 22000\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "    config = {\n",
    "        \"language_code\": language_code,\n",
    "        \"sample_rate_hertz\": sample_rate_hertz,\n",
    "        \"encoding\": encoding,\n",
    "        \"enable_word_confidence\": True,\n",
    "        \"enable_word_time_offsets\": True\n",
    "    }\n",
    "    audio = {\"content\": content}\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    i = 0\n",
    "    for result in response.results:\n",
    "        # First alternative is the most probable result\n",
    "        alternative = result.alternatives[0]\n",
    "        print(t1,u\"Transcript: {}{}\".format(alternative.transcript, i))\n",
    "        for word in alternative.words:\n",
    "          print(u\"Word: {}\".format(word.word))\n",
    "          print(u\"Confidence: {}\".format(word.confidence))\n",
    "          print(\n",
    "            u\"Start time: {} seconds {} nanos\".format(\n",
    "                word.start_time.seconds, word.start_time.nanos\n",
    "                )\n",
    "            )\n",
    "          print(\n",
    "              u\"End time: {} seconds {} nanos\".format(\n",
    "                  word.end_time.seconds, word.end_time.nanos\n",
    "                  )\n",
    "              )\n",
    "\n",
    "        i+=1\n",
    "\n",
    "\n",
    "# for t1 in range(1, 20, 5):\n",
    "#     t2= t1+ 10\n",
    "#     t1 = t1 * 1000 #Works in milliseconds\n",
    "#     t2 = t2 * 1000\n",
    "#     newAudio = Audio[t1:t2]\n",
    "\n",
    "#     newAudio.export('newSong1.wav', format=\"wav\") \n",
    "# play(Audio[0:15*1000])\n",
    "t1=15\n",
    "t2= t1+ 10\n",
    "t1 = t1 * 1000 #Works in milliseconds\n",
    "t2 = t2 * 1000\n",
    "\n",
    "# Audio = AudioSegment.from_mp3(\"/Users/muratguner/Documents/experiments/google_cloud_speech/resources/alices_adventures_64kb_mp3/aliceinwonderland_03_carroll_64kb.mp3\")\n",
    "Audio = AudioSegment.from_mp3(\"/Users/muratguner/Documents/experiments/google_cloud_speech/resources/alices_adventures_64kb_mp3/aliceinwonderland_03_carroll_64kb.mp3\")\n",
    "\n",
    "newAudio = Audio[t1:t2]\n",
    "\n",
    "sample_recognize(newAudio.raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-4f5739c9272e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# get a random word from the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# format the instructions string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    \"\"\"Transcribe speech from recorded from `microphone`.\n",
    "\n",
    "    Returns a dictionary with three keys:\n",
    "    \"success\": a boolean indicating whether or not the API request was\n",
    "               successful\n",
    "    \"error\":   `None` if no error occured, otherwise a string containing\n",
    "               an error message if the API could not be reached or\n",
    "               speech was unrecognizable\n",
    "    \"transcription\": `None` if speech could not be transcribed,\n",
    "               otherwise a string containing the transcribed text\n",
    "    \"\"\"\n",
    "    # check that recognizer and microphone arguments are appropriate type\n",
    "    if not isinstance(recognizer, sr.Recognizer):\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\n",
    "\n",
    "    if not isinstance(microphone, sr.Microphone):\n",
    "        raise TypeError(\"`microphone` must be `Microphone` instance\")\n",
    "\n",
    "    # adjust the recognizer sensitivity to ambient noise and record audio\n",
    "    # from the microphone\n",
    "    with microphone as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    # set up the response object\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    "\n",
    "    # try recognizing the speech in the recording\n",
    "    # if a RequestError or UnknownValueError exception is caught,\n",
    "    #     update the response object accordingly\n",
    "    try:\n",
    "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
    "    except sr.RequestError:\n",
    "        # API was unreachable or unresponsive\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable\"\n",
    "    except sr.UnknownValueError:\n",
    "        # speech was unintelligible\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # set the list of words, maxnumber of guesses, and prompt limit\n",
    "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\n",
    "    NUM_GUESSES = 3\n",
    "    PROMPT_LIMIT = 5\n",
    "\n",
    "    # create recognizer and mic instances\n",
    "    recognizer = sr.Recognizer()\n",
    "    microphone = sr.Microphone()\n",
    "\n",
    "    # get a random word from the list\n",
    "    word = random.choice(WORDS)\n",
    "\n",
    "    # format the instructions string\n",
    "    instructions = (\n",
    "        \"I'm thinking of one of these words:\\n\"\n",
    "        \"{words}\\n\"\n",
    "        \"You have {n} tries to guess which one.\\n\"\n",
    "    ).format(words=', '.join(WORDS), n=NUM_GUESSES)\n",
    "\n",
    "    # show instructions and wait 3 seconds before starting the game\n",
    "    print(instructions)\n",
    "    time.sleep(3)\n",
    "\n",
    "    for i in range(NUM_GUESSES):\n",
    "        # get the guess from the user\n",
    "        # if a transcription is returned, break out of the loop and\n",
    "        #     continue\n",
    "        # if no transcription returned and API request failed, break\n",
    "        #     loop and continue\n",
    "        # if API request succeeded but no transcription was returned,\n",
    "        #     re-prompt the user to say their guess again. Do this up\n",
    "        #     to PROMPT_LIMIT times\n",
    "        for j in range(PROMPT_LIMIT):\n",
    "            print('Guess {}. Speak!'.format(i+1))\n",
    "            guess = recognize_speech_from_mic(recognizer, microphone)\n",
    "            if guess[\"transcription\"]:\n",
    "                break\n",
    "            if not guess[\"success\"]:\n",
    "                break\n",
    "            print(\"I didn't catch that. What did you say?\\n\")\n",
    "\n",
    "        # if there was an error, stop the game\n",
    "        if guess[\"error\"]:\n",
    "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
    "            break\n",
    "\n",
    "        # show the user the transcription\n",
    "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
    "\n",
    "        # determine if guess is correct and if any attempts remain\n",
    "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\n",
    "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
    "\n",
    "        # determine if the user has won the game\n",
    "        # if not, repeat the loop if user has more attempts\n",
    "        # if no attempts left, the user loses the game\n",
    "        if guess_is_correct:\n",
    "            print(\"Correct! You win!\".format(word))\n",
    "            break\n",
    "        elif user_has_more_attempts:\n",
    "            print(\"Incorrect. Try again.\\n\")\n",
    "        else:\n",
    "            print(\"Sorry, you lose!\\nI was thinking of '{}'.\".format(word))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the audio file path\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/experiments/meet_up_presentation/ispeech/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/experiments/meet_up_presentation/ispeech/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/experiments/meet_up_presentation/ispeech/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Documents/experiments/meet_up_presentation/ispeech/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-db46ed2edd53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter the audio file path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msilence_based_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/experiments/meet_up_presentation/ispeech/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/experiments/meet_up_presentation/ispeech/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as  sr \n",
    "import  os\n",
    "from pydub import AudioSegment\n",
    "from  pydub.silence  import  split_on_silence\n",
    "from pydub.playback import play\n",
    "\n",
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "\n",
    "def silence_based_conversion(path = \"\"): \n",
    "\n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_mp3(path)[0:45*1000] \n",
    "\n",
    "    # open a file where we will concatenate \n",
    "    # and store the recognized text \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "\n",
    "    # split track where silence is 0.5 seconds \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 750, \n",
    "\n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -50\n",
    "    ) \n",
    "\n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "\n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('audio_chunks') \n",
    "\n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    for chunk in chunks:\t\n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "\n",
    "        # add 0.5 sec silence to beginning and \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "\n",
    "        # export audio chunk and save it in \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "\n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "\n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "\n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "\n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "\n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            # r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.listen(source) \n",
    "\n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\".\") \n",
    "\n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "\n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "\n",
    "        i += 1\n",
    "\n",
    "    os.chdir('..') \n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    print('Enter the audio file path') \n",
    "\n",
    "    path = input() \n",
    "\n",
    "    silence_based_conversion(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as  sr \n",
    "import  os\n",
    "from pydub import AudioSegment\n",
    "from  pydub.silence  import  split_on_silence\n",
    "from pydub.playback import play\n",
    "\n",
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "\n",
    "def silence_based_conversion(path = \"\"): \n",
    "\n",
    "\t# open the audio file stored in \n",
    "\t# the local system as a wav file. \n",
    "\tsong = AudioSegment.from_mp3(path)[0:45*1000] \n",
    "\n",
    "\t# open a file where we will concatenate \n",
    "\t# and store the recognized text \n",
    "\tfh = open(\"recognized.txt\", \"w+\") \n",
    "\t\t\n",
    "\t# split track where silence is 0.5 seconds \n",
    "\t# or more and get chunks \n",
    "\tchunks = split_on_silence(song, \n",
    "\t\t# must be silent for at least 0.5 seconds \n",
    "\t\t# or 500 ms. adjust this value based on user \n",
    "\t\t# requirement. if the speaker stays silent for \n",
    "\t\t# longer, increase this value. else, decrease it. \n",
    "\t\tmin_silence_len = 750, \n",
    "\n",
    "\t\t# consider it silent if quieter than -16 dBFS \n",
    "\t\t# adjust this per requirement \n",
    "\t\tsilence_thresh = -50\n",
    "\t) \n",
    "\n",
    "\t# create a directory to store the audio chunks. \n",
    "\ttry: \n",
    "\t\tos.mkdir('audio_chunks') \n",
    "\texcept(FileExistsError): \n",
    "\t\tpass\n",
    "\n",
    "\t# move into the directory to \n",
    "\t# store the audio files. \n",
    "\tos.chdir('audio_chunks') \n",
    "\n",
    "\ti = 0\n",
    "\t# process each chunk \n",
    "\tfor chunk in chunks:\t\n",
    "\t\t# Create 0.5 seconds silence chunk \n",
    "\t\tchunk_silent = AudioSegment.silent(duration = 10) \n",
    "\n",
    "\t\t# add 0.5 sec silence to beginning and \n",
    "\t\t# end of audio chunk. This is done so that \n",
    "\t\t# it doesn't seem abruptly sliced. \n",
    "\t\taudio_chunk = chunk_silent + chunk + chunk_silent \n",
    "\n",
    "\t\t# export audio chunk and save it in \n",
    "\t\t# the current directory. \n",
    "\t\tprint(\"saving chunk{0}.wav\".format(i)) \n",
    "\t\t# specify the bitrate to be 192 k \n",
    "\t\taudio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "\n",
    "\t\t# the name of the newly created chunk \n",
    "\t\tfilename = 'chunk'+str(i)+'.wav'\n",
    "\n",
    "\t\tprint(\"Processing chunk \"+str(i)) \n",
    "\n",
    "\t\t# get the name of the newly created chunk \n",
    "\t\t# in the AUDIO_FILE variable for later use. \n",
    "\t\tfile = filename \n",
    "\n",
    "\t\t# create a speech recognition object \n",
    "\t\tr = sr.Recognizer() \n",
    "\n",
    "\t\t# recognize the chunk \n",
    "\t\twith sr.AudioFile(file) as source: \n",
    "\t\t\t# remove this if it is not working \n",
    "\t\t\t# correctly. \n",
    "\t\t\t# r.adjust_for_ambient_noise(source) \n",
    "\t\t\taudio_listened = r.listen(source) \n",
    "\n",
    "\t\ttry: \n",
    "\t\t\t# try converting it to text \n",
    "\t\t\trec = r.recognize_google(audio_listened) \n",
    "\t\t\t# write the output to the file. \n",
    "\t\t\tfh.write(rec+\".\") \n",
    "\n",
    "\t\t# catch any errors. \n",
    "\t\texcept sr.UnknownValueError: \n",
    "\t\t\tprint(\"Could not understand audio\") \n",
    "\n",
    "\t\texcept sr.RequestError as e: \n",
    "\t\t\tprint(\"Could not request results. check your internet connection\") \n",
    "\n",
    "\t\ti += 1\n",
    "\n",
    "\tos.chdir('..') \n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "\t\t\n",
    "\tprint('Enter the audio file path') \n",
    "\n",
    "\tpath = input() \n",
    "\n",
    "\tsilence_based_conversion(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as  sr \n",
    "import  os\n",
    "from pydub import AudioSegment\n",
    "from  pydub.silence  import  split_on_silence\n",
    "from pydub.playback import play\n",
    "\n",
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "\n",
    "def silence_based_conversion(path = \"\"): \n",
    "\n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_mp3(path)[0:45*1000] \n",
    "\n",
    "    # open a file where we will concatenate \n",
    "    # and store the recognized text \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "\n",
    "    # split track where silence is 0.5 seconds \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 750, \n",
    "\n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -50\n",
    "    ) \n",
    "\n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "\n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('audio_chunks') \n",
    "\n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    for chunk in chunks:\t\n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "\n",
    "        # add 0.5 sec silence to beginning and \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "\n",
    "        # export audio chunk and save it in \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "\n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "\n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "\n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "\n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "\n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            # r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.listen(source) \n",
    "\n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\".\") \n",
    "\n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "\n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "\n",
    "        i += 1\n",
    "\n",
    "    os.chdir('..') \n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    print('Enter the audio file path') \n",
    "\n",
    "    path = input() \n",
    "\n",
    "    silence_based_conversion(path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_to_text",
   "language": "python",
   "name": "speech_to_text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
